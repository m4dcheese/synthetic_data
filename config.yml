# ----- ----- ----- ----- ----- ----- ----- ----- -----
# ----- ----- ----- ----- ----- ----- ----- ----- -----

# ----- ----- ----- ----- T R A I N I N G
training: 
  total_iterations: 100
  batch_size: 32
  mlps_per_batch: 4 # needs to be a factor of batch_size
  batches_per_iteration: 100
  num_data_workers: 0
  sigma: 0.00001
  world_size: 0 # 0 -> cpu, 1 -> 1-GPU, 1< -> multi-GPU
  data_prefetch_factor: 10

# ----- ----- ----- ----- O P T I M I Z E R
optimizer:
  optimizer_str: "AdamW"
  lr: 0.0001
  weight_decay: 0.0001

# ----- ----- ----- ----- C R I T E R I O N
criterion:
  criterion_str: "mse"

# ----- ----- ----- ----- D A T A
data: 
  features:
    min: 1
    max: 10
  classes:
    min: 2
    max: 2
  samples: 
    min: 100
    max: 1000


# ----- ----- ----- ----- M L P
target_mlp:
  num_layers: 3 # input + hidden + output
  hidden_dim: 128
  output_dim: 1
  activation_str: relu
  bias: true
  initialization: uniform

# ----- ----- ----- ----- M O D E L
cfm: 
  transformer: 
    encoder: 
      num_layers: 2
      d_model: 512
      nhead: 8
      dim_feedforward: 2048
      dropout: 0.1
      activation_str: relu
      layer_norm_eps: 0.00001
      batch_first: true
      norm_first: false
      bias: true

    decoder:
      num_layers: 2
      d_model: 512
      nhead: 8
      dim_feedforward: 2048
      dropout: 0.1
      activation_str: relu
      layer_norm_eps: 0.00001
      batch_first: true
      norm_first: false
      bias: true

  data_projection: 
    num_layers: 1
    hidden_dim: 512

  weight_projection: 
    num_layers: 1
    hidden_dim: 512

  positional_encoding: 
    dropout: 0.1

  prediction_head:
    num_layers: 2
    hidden_dim: 512
    # output_dim: 1
    activation_str: relu
    bias: true


results:
  base_path: "results/"